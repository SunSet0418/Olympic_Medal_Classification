{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model (Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunset/.pyenv/versions/anaconda3-5.0.1/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data len : 30181\n",
      "0 Cost :  46730.523\n",
      "100 Cost :  798.2428\n",
      "200 Cost :  297.93716\n",
      "300 Cost :  286.85526\n",
      "400 Cost :  273.96252\n",
      "500 Cost :  259.7038\n",
      "600 Cost :  244.4413\n",
      "700 Cost :  228.48949\n",
      "800 Cost :  212.12892\n",
      "900 Cost :  195.61227\n",
      "1000 Cost :  179.16641\n",
      "1100 Cost :  162.99374\n",
      "1200 Cost :  147.27187\n",
      "1300 Cost :  132.15327\n",
      "1400 Cost :  117.765205\n",
      "1500 Cost :  104.20969\n",
      "1600 Cost :  91.56381\n",
      "1700 Cost :  79.88036\n",
      "1800 Cost :  69.1894\n",
      "1900 Cost :  59.499565\n",
      "2000 Cost :  50.80024\n",
      "2100 Cost :  43.063892\n",
      "2200 Cost :  36.24873\n",
      "2300 Cost :  30.30139\n",
      "2400 Cost :  25.15987\n",
      "2500 Cost :  20.756199\n",
      "2600 Cost :  17.019138\n",
      "2700 Cost :  13.876526\n",
      "2800 Cost :  11.257384\n",
      "2900 Cost :  9.093615\n",
      "3000 Cost :  7.321371\n",
      "3100 Cost :  5.8819976\n",
      "3200 Cost :  4.722609\n",
      "3300 Cost :  3.7963493\n",
      "3400 Cost :  3.0623448\n",
      "3500 Cost :  2.4854662\n",
      "3600 Cost :  2.0358996\n",
      "3700 Cost :  1.6886387\n",
      "3800 Cost :  1.4229171\n",
      "3900 Cost :  1.2216487\n",
      "4000 Cost :  1.0708827\n",
      "4100 Cost :  0.959315\n",
      "4200 Cost :  0.8778544\n",
      "4300 Cost :  0.8192469\n",
      "4400 Cost :  0.7777564\n",
      "4500 Cost :  0.748896\n",
      "4600 Cost :  0.72919995\n",
      "4700 Cost :  0.71603113\n",
      "4800 Cost :  0.70741695\n",
      "4900 Cost :  0.7019111\n",
      "5000 Cost :  0.6984757\n",
      "5100 Cost :  0.69638413\n",
      "5200 Cost :  0.69514084\n",
      "5300 Cost :  0.6944171\n",
      "5400 Cost :  0.69400144\n",
      "5500 Cost :  0.69376236\n",
      "5600 Cost :  0.6936205\n",
      "5700 Cost :  0.6935298\n",
      "5800 Cost :  0.69346434\n",
      "5900 Cost :  0.69341046\n",
      "6000 Cost :  0.6933608\n",
      "6100 Cost :  0.6933118\n",
      "6200 Cost :  0.69326186\n",
      "6300 Cost :  0.69320995\n",
      "6400 Cost :  0.6931557\n",
      "6500 Cost :  0.6930989\n",
      "6600 Cost :  0.6930395\n",
      "6700 Cost :  0.69297713\n",
      "6800 Cost :  0.69291174\n",
      "6900 Cost :  0.69284326\n",
      "7000 Cost :  0.6927715\n",
      "7100 Cost :  0.6926964\n",
      "7200 Cost :  0.6926177\n",
      "7300 Cost :  0.69253516\n",
      "7400 Cost :  0.6924489\n",
      "7500 Cost :  0.69235855\n",
      "7600 Cost :  0.6922641\n",
      "7700 Cost :  0.6921652\n",
      "7800 Cost :  0.6920618\n",
      "7900 Cost :  0.6919536\n",
      "8000 Cost :  0.6918406\n",
      "8100 Cost :  0.69172245\n",
      "8200 Cost :  0.69159895\n",
      "8300 Cost :  0.6914701\n",
      "8400 Cost :  0.6913355\n",
      "8500 Cost :  0.6911951\n",
      "8600 Cost :  0.6910485\n",
      "8700 Cost :  0.6908958\n",
      "8800 Cost :  0.6907365\n",
      "8900 Cost :  0.69057053\n",
      "9000 Cost :  0.6903976\n",
      "9100 Cost :  0.69021773\n",
      "9200 Cost :  0.69003046\n",
      "9300 Cost :  0.6898358\n",
      "9400 Cost :  0.6896335\n",
      "9500 Cost :  0.68942326\n",
      "9600 Cost :  0.68920505\n",
      "9700 Cost :  0.6889788\n",
      "9800 Cost :  0.6887442\n",
      "9900 Cost :  0.6885011\n",
      "10000 Cost :  0.6882495\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "data_x1 = []\n",
    "data_x2 = []\n",
    "data_x3 = []\n",
    "\n",
    "data_y = []\n",
    "\n",
    "train_x1 = tf.placeholder(tf.float32)\n",
    "train_x2 = tf.placeholder(tf.float32)\n",
    "train_x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "train_y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]))\n",
    "w2 = tf.Variable(tf.random_normal([1]))\n",
    "w3 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = train_x1 * w1 + train_x2 * w2 + train_x3 * w3 + bias\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - train_y))\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "def read_data():\n",
    "    dataset = []\n",
    "    with open('dataset/athlete_events.csv', 'r', encoding='utf-8') as f:\n",
    "\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            json = {}\n",
    "\n",
    "            if row[3] == 'NA' or row[4] == 'NA' or row[5] == 'NA' or row[14] == 'NA':\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                json['age'] = row[3]\n",
    "                json['height'] = row[4]\n",
    "                json['weight'] = row[5]\n",
    "                json['medal'] = row[14]\n",
    "                dataset.append(json)\n",
    "\n",
    "        del dataset[0]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def set_train_data():\n",
    "    datas = read_data()\n",
    "\n",
    "    for row in datas:\n",
    "        data_x1.append([float(row['age'])])\n",
    "        data_x2.append([float(row['height'])])\n",
    "        data_x3.append([float(row['weight'])])\n",
    "        if row['medal'] == 'Gold':\n",
    "            data_y.append([1])\n",
    "        elif row['medal'] == 'Silver':\n",
    "            data_y.append([2])\n",
    "        elif row['medal'] == 'Bronze':\n",
    "            data_y.append([3])\n",
    "        else:\n",
    "            data_y.append(row['medal'])\n",
    "\n",
    "    print(\"data len : \"+str(len(data_x1)))\n",
    "\n",
    "    # print(data_x1)\n",
    "    # print(data_x2)\n",
    "    # print(data_x3)\n",
    "    # print(data_y)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = \"./checkpoints/olympic_model.ckpt\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    set_train_data()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "\n",
    "        cost_v, hyp_v, _ = sess.run([cost, hypothesis, train], feed_dict={train_x1 : data_x1, train_x2 : data_x2, train_x3 : data_x3, train_y : data_y})\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "\n",
    "            print(step, \"Cost : \", cost_v)\n",
    "            \n",
    "    saver.save(sess, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "\n",
    "data_x1 = []\n",
    "data_x2 = []\n",
    "data_x3 = []\n",
    "\n",
    "data_y = []\n",
    "\n",
    "train_x1 = tf.placeholder(tf.float32)\n",
    "train_x2 = tf.placeholder(tf.float32)\n",
    "train_x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "train_y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1, 15000]))\n",
    "w2 = tf.Variable(tf.random_normal([15000, 15000]))\n",
    "w3 = tf.Variable(tf.random_normal([15000, 3]))\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([15000]))\n",
    "b2 = tf.Variable(tf.random_normal([15000]))\n",
    "b3 = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "l1 = tf.nn.relu(tf.add(tf.matmul(train_x1, w1), b1))\n",
    "l2 = tf.nn.relu(tf.add(tf.matmul(l1, w2), b2))\n",
    "hypothesis = tf.add(tf.matmul(l2, w3), b3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=train_y))\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "def read_data():\n",
    "    dataset = []\n",
    "    with open('dataset/athlete_events.csv', 'r', encoding='utf-8') as f:\n",
    "\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            json = {}\n",
    "\n",
    "            if row[3] == 'NA' or row[4] == 'NA' or row[5] == 'NA' or row[14] == 'NA':\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                json['age'] = row[3]\n",
    "                json['height'] = row[4]\n",
    "                json['weight'] = row[5]\n",
    "                json['medal'] = row[14]\n",
    "                dataset.append(json)\n",
    "\n",
    "        del dataset[0]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def set_train_data():\n",
    "    datas = read_data()\n",
    "\n",
    "    for row in datas:\n",
    "        data_x1.append([float(row['age'])])\n",
    "        data_x2.append([float(row['height'])])\n",
    "        data_x3.append([float(row['weight'])])\n",
    "        if row['medal'] == 'Gold':\n",
    "            data_y.append([1])\n",
    "        elif row['medal'] == 'Silver':\n",
    "            data_y.append([2])\n",
    "        elif row['medal'] == 'Bronze':\n",
    "            data_y.append([3])\n",
    "        else:\n",
    "            data_y.append(row['medal'])\n",
    "\n",
    "    print(\"data len : \"+str(len(data_x1)))\n",
    "\n",
    "    # print(data_x1)\n",
    "    # print(data_x2)\n",
    "    # print(data_x3)\n",
    "    # print(data_y)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    set_train_data()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        print(\"Leaning Start!\")\n",
    "\n",
    "        cost_v, hyp_v, _ = sess.run([cost, hypothesis, train], feed_dict={train_x1 : data_x1, train_x2 : data_x2, train_x3 : data_x3, train_y : data_y})\n",
    "\n",
    "        print(step, \"Cost : \", cost_v)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
