{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model (DNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunset/.pyenv/versions/anaconda3-5.0.1/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "\n",
    "train_x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "train_y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    with open('dataset/athlete_events.csv', 'r', encoding='utf-8') as f:\n",
    "\n",
    "        reader = csv.reader(f)\n",
    "\n",
    "        for row in reader:\n",
    "            \n",
    "            tmp = []\n",
    "\n",
    "            if row[3] == 'NA' or row[4] == 'NA' or row[5] == 'NA' or row[14] == 'NA':\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                tmp.append(row[3])\n",
    "                tmp.append(row[4])\n",
    "                tmp.append(row[5])\n",
    "                \n",
    "                data_x.append(tmp)\n",
    "                \n",
    "                if row[14] == 'Gold':\n",
    "                    data_y.append([1])\n",
    "                elif row[14] == 'Silver':\n",
    "                    data_y.append([2])\n",
    "                elif row[14] == 'Bronze':\n",
    "                    data_y.append([3])\n",
    "                else:\n",
    "                    data_y.append(row[14])\n",
    "                \n",
    "\n",
    "        del data_x[0]\n",
    "        del data_y[0]\n",
    "        \n",
    "        global test_x\n",
    "        test_x = data_x[29181:]\n",
    "        del data_x[29181:]\n",
    "    \n",
    "        global test_y\n",
    "        test_y = data_y[29181:]\n",
    "        del data_y[29181:]\n",
    "\n",
    "        x_shape = np.array(data_x)\n",
    "        y_shape = np.array(data_y)\n",
    "\n",
    "        tx_shape = np.array(test_x)\n",
    "        ty_shape = np.array(test_y)\n",
    "\n",
    "        print(\"data_X Shape : \", x_shape.shape)\n",
    "        print(\"data_Y Shape : \", y_shape.shape)\n",
    "\n",
    "        print(\"tdata_X Shape : \", tx_shape.shape)\n",
    "        print(\"tdata_Y Shape : \", ty_shape.shape)\n",
    "\n",
    "\n",
    "# def set_train_data():\n",
    "    \n",
    "#     datas = read_data()\n",
    "\n",
    "#     for row in datas:\n",
    "#         tmp = []\n",
    "\n",
    "#         tmp.append(float(row['age']))\n",
    "#         tmp.append(float(row['height']))\n",
    "#         tmp.append(float(row['weight']))\n",
    "\n",
    "#         data_x.append(tmp)\n",
    "\n",
    "        \n",
    "\n",
    "#     global test_x\n",
    "#     test_x = data_x[29181:]\n",
    "#     del data_x[29181:]\n",
    "    \n",
    "#     global test_y\n",
    "#     test_y = data_y[29181:]\n",
    "#     del data_y[29181:]\n",
    "\n",
    "#     x_shape = np.array(data_x)\n",
    "#     y_shape = np.array(data_y)\n",
    "\n",
    "#     tx_shape = np.array(test_x)\n",
    "#     ty_shape = np.array(test_y)\n",
    "\n",
    "#     print(\"data_X Shape : \", x_shape.shape)\n",
    "#     print(\"data_Y Shape : \", y_shape.shape)\n",
    "\n",
    "#     print(\"tdata_X Shape : \", tx_shape.shape)\n",
    "#     print(\"tdata_Y Shape : \", ty_shape.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_X Shape :  (29181, 3)\n",
      "data_Y Shape :  (29181, 1)\n",
      "tdata_X Shape :  (1000, 3)\n",
      "tdata_Y Shape :  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal([3, 5]))\n",
    "b1 = tf.Variable(tf.random_normal([5]))\n",
    "l1 = tf.nn.relu(tf.add(tf.matmul(train_x, w1), b1))\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([5, 5]))\n",
    "b2 = tf.Variable(tf.random_normal([5]))\n",
    "l2 = tf.nn.relu(tf.add(tf.matmul(l1, w2), b2))\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([5, 5]))\n",
    "b3 = tf.Variable(tf.random_normal([5]))\n",
    "l3 = tf.nn.relu(tf.add(tf.matmul(l2, w3), b3))\n",
    "\n",
    "w4 = tf.Variable(tf.random_normal([5, 1]))\n",
    "b4 = tf.Variable(tf.random_normal([1]))\n",
    "hypothesis = tf.add(tf.matmul(l3, w4), b4)\n",
    "\n",
    "cost = tf.losses.mean_squared_error(labels=train_y, predictions=hypothesis)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = \"./checkpoints/olympic_nn_model.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Start!\n",
      "STEP : 0 Cost : 767.45294\n",
      "STEP : 200 Cost : 0.70070976\n",
      "STEP : 400 Cost : 0.67703164\n",
      "STEP : 600 Cost : 0.6729292\n",
      "STEP : 800 Cost : 0.67259765\n",
      "STEP : 1000 Cost : 0.67258275\n",
      "STEP : 1200 Cost : 0.6725801\n",
      "STEP : 1400 Cost : 0.6725768\n",
      "STEP : 1600 Cost : 0.6725731\n",
      "STEP : 1800 Cost : 0.6725691\n",
      "STEP : 2000 Cost : 0.67256343\n",
      "STEP : 2200 Cost : 0.6725578\n",
      "STEP : 2400 Cost : 0.67255384\n",
      "STEP : 2600 Cost : 0.67255086\n",
      "STEP : 2800 Cost : 0.672549\n",
      "STEP : 3000 Cost : 0.6725471\n",
      "STEP : 3200 Cost : 0.6725455\n",
      "STEP : 3400 Cost : 0.67254454\n",
      "STEP : 3600 Cost : 0.67254364\n",
      "STEP : 3800 Cost : 0.6725433\n",
      "STEP : 4000 Cost : 0.672543\n",
      "STEP : 4200 Cost : 0.6725427\n",
      "STEP : 4400 Cost : 0.6725418\n",
      "STEP : 4600 Cost : 0.6725409\n",
      "STEP : 4800 Cost : 0.6725406\n",
      "STEP : 5000 Cost : 0.6725404\n",
      "STEP : 5200 Cost : 0.6725402\n",
      "STEP : 5400 Cost : 0.6725399\n",
      "STEP : 5600 Cost : 0.67253965\n",
      "STEP : 5800 Cost : 0.67253923\n",
      "STEP : 6000 Cost : 0.67253894\n",
      "STEP : 6200 Cost : 0.67253864\n",
      "STEP : 6400 Cost : 0.6725383\n",
      "STEP : 6600 Cost : 0.6725378\n",
      "STEP : 6800 Cost : 0.6725373\n",
      "STEP : 7000 Cost : 0.6725369\n",
      "STEP : 7200 Cost : 0.67253625\n",
      "STEP : 7400 Cost : 0.6725357\n",
      "STEP : 7600 Cost : 0.67253506\n",
      "STEP : 7800 Cost : 0.6725344\n",
      "STEP : 8000 Cost : 0.67253345\n",
      "STEP : 8200 Cost : 0.67253226\n",
      "STEP : 8400 Cost : 0.67253107\n",
      "STEP : 8600 Cost : 0.6725298\n",
      "STEP : 8800 Cost : 0.67252666\n",
      "STEP : 9000 Cost : 0.6725252\n",
      "STEP : 9200 Cost : 0.67252374\n",
      "STEP : 9400 Cost : 0.67252225\n",
      "STEP : 9600 Cost : 0.6725206\n",
      "STEP : 9800 Cost : 0.67251873\n",
      "STEP : 10000 Cost : 0.6725169\n",
      "Saving Model...\n",
      "Save Successful!\n",
      "Model Test...\n",
      "[array([[1.999313]], dtype=float32)]\n",
      "Checking Accuracy...\n",
      "Accuracy : 100.0 %\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # TensorBoard Setting\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "    summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./log')\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Learning Start\n",
    "    print(\"Learning Start!\")\n",
    "    for step in range(10001):\n",
    "        cost_v, _ = sess.run([cost, train], feed_dict={train_x: data_x, train_y: data_y})\n",
    "        if step % 200 == 0:\n",
    "            print(\"STEP :\", step, \"Cost :\", cost_v)\n",
    "            \n",
    "            \n",
    "    # Model Save\n",
    "    print(\"Saving Model...\")        \n",
    "    saver.save(sess, save_path)\n",
    "    print(\"Save Successful!\")\n",
    "\n",
    "    # Model Testing\n",
    "    print(\"Model Test...\")\n",
    "    result = sess.run([hypothesis], feed_dict={train_x: [[22.0, 185.0, 82.0]]})\n",
    "    print(result)\n",
    "\n",
    "    # Check Accuracy\n",
    "    print(\"Checking Accuracy...\")\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(train_y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy :\",sess.run(accuracy, feed_dict={train_x: test_x, train_y: test_y}) * 100,\"%\")\n",
    "\n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/olympic_nn_model.ckpt\n",
      "Weight : 75\n",
      "Height : 182\n",
      "How Old : 31\n",
      "Model Test...\n",
      "1.9993827\n",
      "Silver Medal\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Model Restore\n",
    "saver.restore(sess, save_path)\n",
    "    \n",
    "# Input Values\n",
    "weight = input(\"Weight : \")\n",
    "height = input(\"Height : \")\n",
    "old = input(\"How Old : \")\n",
    "\n",
    "# Model Testing\n",
    "print(\"Model Test...\")\n",
    "result = sess.run(hypothesis, feed_dict={train_x: [[old, height, weight]]})[0][0]\n",
    "\n",
    "print(result)\n",
    "\n",
    "if round(result) == 1:\n",
    "    print(\"Gold Medal\")\n",
    "\n",
    "elif round(result) == 2:\n",
    "    print(\"Silver Medal\")\n",
    "    \n",
    "elif round(result) == 3:\n",
    "    print(\"Bronze Medal\")\n",
    "\n",
    "else:\n",
    "    print(\"No Medal\")\n",
    "\n",
    "print(\"Finished\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
